

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Understanding Fully Convolutional Neural Networks &#8212; Learning Parameterizations with Ross-22</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'notebooks/Understanding_Fully_Convolutional_Neural_Networks';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Running Parameterized FCNNs" href="Running_Parameterized_FCNNs.html" />
    <link rel="prev" title="Applying Filtering and Coarse-Graining to Generate Low-Resolution Datasets" href="Applying_Filtering_and_Coarse-Graining_to_Generate_Low_Resolution_Datasets.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
    
    
      
    
    
    <img src="../_static/newlogo.png" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="../_static/newlogo.png" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    Introduction
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="Running_High_Resolution_Simulations_With_pyqg.html">Running Simulations and Making Analyzations With pyqg</a></li>
<li class="toctree-l1"><a class="reference internal" href="Applying_Filtering_and_Coarse-Graining_to_Generate_Low_Resolution_Datasets.html">Applying Filtering and Coarse-Graining to Generate Low-Resolution Datasets</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Understanding Fully Convolutional Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="Running_Parameterized_FCNNs.html">Running Parameterized FCNNs</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/notebooks/Understanding_Fully_Convolutional_Neural_Networks.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Understanding Fully Convolutional Neural Networks</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#initializing-and-instantiating-fcnns">Initializing and Instantiating FCNNs</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-preprocessing-and-preparation">Data Preprocessing and Preparation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#feature-extraction">Feature Extraction</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#standardization">Standardization</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#training-fcnns">Training FCNNs</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#saving-and-loading-fcnns">Saving and Loading FCNNs</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#running-predictions">Running Predictions</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <div class="tex2jax_ignore mathjax_ignore section" id="understanding-fully-convolutional-neural-networks">
<h1>Understanding Fully Convolutional Neural Networks<a class="headerlink" href="#understanding-fully-convolutional-neural-networks" title="Permalink to this heading">#</a></h1>
<p>Now that we have generated coarsened, low-resolution datasets, we can now feed them as training data into our parameterized machine learning (ML) models and begin running predictions against unseen datasets. In this tutorial series, we will focus on one category of ML models, fully convolutional neural networks (FCNNs), though there are other strata of models that can be employed (and are explored within the paper) including hybrid linear and symbolic regression using genetic programming. Before we begin running these models and making predictions, in this notebook, we will take the time to better our understanding of FCNNs including the initialization process, data preprocessing, undergoing training sessions and generating predictions.</p>
<p>The local code that we utilize for running parameterized ML models resides within this <a class="reference external" href="https://github.com/m2lines/pyqg_parameterization_benchmarks">repository</a>. Our main focus of interest is in the files <code class="docutils literal notranslate"><span class="pre">neural_networks.py</span></code> and <code class="docutils literal notranslate"><span class="pre">utils.py</span></code>.</p>
<div class="section" id="initializing-and-instantiating-fcnns">
<h2>Initializing and Instantiating FCNNs<a class="headerlink" href="#initializing-and-instantiating-fcnns" title="Permalink to this heading">#</a></h2>
<p>Starting at a high level, within <code class="docutils literal notranslate"><span class="pre">neural</span> <span class="pre">networks.py</span></code>, there sits the <code class="docutils literal notranslate"><span class="pre">FCNNParameterization</span></code> class. We use this class to generate parameterized FCNN models on which we can train and make predictions.</p>
<p>The function that sets up this initial creation is the class method <code class="docutils literal notranslate"><span class="pre">train_on()</span></code> which takes in the dataset that the models will be initially trained on, the path to save the models to as well as the inputs and targets we are training on as strings.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># neural_networks.py:244</span>
<span class="k">class</span> <span class="nc">FCNNParameterization</span><span class="p">(</span><span class="n">Parameterization</span><span class="p">):</span>
    
<span class="c1"># neural_networks.py:281:287</span>
<span class="nd">@classmethod</span>
<span class="k">def</span> <span class="nf">train_on</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">directory</span><span class="p">,</span>
        <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;q&#39;</span><span class="p">,</span><span class="s1">&#39;u&#39;</span><span class="p">,</span><span class="s1">&#39;v&#39;</span><span class="p">],</span> 
        <span class="n">targets</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;q_subgrid_forcing&#39;</span><span class="p">],</span> <span class="c1"># See {INSERT SECTION REFERENCE} for valid target values of sugrid forcing and flux</span>
        <span class="n">num_epochs</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
        <span class="n">zero_mean</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;circular&#39;</span><span class="p">,</span> <span class="o">**</span><span class="n">kw</span><span class="p">):</span> <span class="c1"># Accepts values &#39;same&#39;, &#39;circuluar&#39;, or None</span>
</pre></div>
</div>
</div>
</div>
<p>We can also pass in arguments for additional parameters including the number of epochs, whether the final output layers should be constrained to have zero spatial mean when predicting the subgrid forcing target, and padding technique. This method then creates two <code class="docutils literal notranslate"><span class="pre">FullyCNN</span></code> objects, one for each layer of the quasigeostrophic model on which we ran simulations on.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># neural_networks.py:289:299</span>
<span class="n">layers</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">lev</span><span class="p">))</span>

<span class="n">models</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">FullyCNN</span><span class="p">(</span>
        <span class="p">[(</span><span class="n">feat</span><span class="p">,</span> <span class="n">zi</span><span class="p">)</span> <span class="k">for</span> <span class="n">feat</span> <span class="ow">in</span> <span class="n">inputs</span> <span class="k">for</span> <span class="n">zi</span> <span class="ow">in</span> <span class="n">layers</span><span class="p">],</span>
        <span class="p">[(</span><span class="n">feat</span><span class="p">,</span> <span class="n">z</span><span class="p">)</span> <span class="k">for</span> <span class="n">feat</span> <span class="ow">in</span> <span class="n">targets</span><span class="p">],</span>
        <span class="n">zero_mean</span><span class="o">=</span><span class="n">zero_mean</span><span class="p">,</span>
        <span class="n">padding</span><span class="o">=</span><span class="n">padding</span> 

    <span class="p">)</span> <span class="k">for</span> <span class="n">z</span> <span class="ow">in</span> <span class="n">layers</span>
<span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>By default, each FCNN model has 8 fully convolutional layers (128 and 64 filters for the first two layers, respectively and 32 thereafter), ReLU activations, batch normalization after all immediate layers, and circular padding due to the periodicity of the domain.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># neural_networks.py:14:23</span>
<span class="k">class</span> <span class="nc">FullyCNN</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Pytorch class defining our CNN architecture, plus some helpers for</span>
<span class="sd">    dealing with constraints and scaling.&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;circular&#39;</span><span class="p">,</span> <span class="n">zero_mean</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">padding</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">padding_5</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">padding_3</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">elif</span> <span class="n">padding</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;same&#39;</span><span class="p">,</span> <span class="s1">&#39;circular&#39;</span><span class="p">]:</span>
            <span class="n">padding_5</span> <span class="o">=</span> <span class="mi">2</span>
            <span class="n">padding_3</span> <span class="o">=</span> <span class="mi">1</span>

<span class="c1"># neural_networks.py:35:42</span>
<span class="n">block1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_make_subblock</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">n_in</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="n">padding_5</span><span class="p">,</span> <span class="o">**</span><span class="n">kw</span><span class="p">))</span>
<span class="n">block2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_make_subblock</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="n">padding_5</span><span class="p">,</span> <span class="o">**</span><span class="n">kw</span><span class="p">))</span>
<span class="n">block3</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_make_subblock</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="n">padding_3</span><span class="p">,</span> <span class="o">**</span><span class="n">kw</span><span class="p">))</span>
<span class="n">block4</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_make_subblock</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="n">padding_3</span><span class="p">,</span> <span class="o">**</span><span class="n">kw</span><span class="p">))</span>
<span class="n">block5</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_make_subblock</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="n">padding_3</span><span class="p">,</span> <span class="o">**</span><span class="n">kw</span><span class="p">))</span>
<span class="n">block6</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_make_subblock</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="n">padding_3</span><span class="p">,</span> <span class="o">**</span><span class="n">kw</span><span class="p">))</span>
<span class="n">block7</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_make_subblock</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="n">padding_3</span><span class="p">,</span> <span class="o">**</span><span class="n">kw</span><span class="p">))</span>
<span class="n">conv8</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">n_out</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="n">padding_3</span><span class="p">)</span>

<span class="c1"># neural_networks.py:54:55</span>
<span class="k">def</span> <span class="nf">_make_subblock</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">conv</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">conv</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">conv</span><span class="o">.</span><span class="n">out_channels</span><span class="p">)]</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="data-preprocessing-and-preparation">
<h2>Data Preprocessing and Preparation<a class="headerlink" href="#data-preprocessing-and-preparation" title="Permalink to this heading">#</a></h2>
<div class="section" id="feature-extraction">
<h3>Feature Extraction<a class="headerlink" href="#feature-extraction" title="Permalink to this heading">#</a></h3>
<p>Upon initializing the models, the method <code class="docutils literal notranslate"><span class="pre">train_on()</span></code> then trains the newly created models on the training dataset that was passed in. However, the raw training data must be preprocessed and prepared in order to be fed into the models for training. This is done by first extracting the relevant input and target feature values from the training dataset.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># neural_networks.py:308:309</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">extract_inputs</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">extract_targets</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>

<span class="c1"># neural_networks.py:57:66</span>
<span class="k">def</span> <span class="nf">extract_vars</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">features</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">):</span>
    <span class="n">ex</span> <span class="o">=</span> <span class="n">FeatureExtractor</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>

    <span class="n">arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span>
        <span class="n">np</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="n">ex</span><span class="p">(</span><span class="n">feat</span><span class="p">),</span> <span class="n">z</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">3</span><span class="p">)</span> <span class="k">for</span> <span class="n">feat</span><span class="p">,</span> <span class="n">z</span> <span class="ow">in</span> <span class="n">features</span>
    <span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">3</span><span class="p">)</span>

    <span class="n">arr</span> <span class="o">=</span> <span class="n">arr</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">features</span><span class="p">),</span> <span class="n">ex</span><span class="o">.</span><span class="n">nx</span><span class="p">,</span> <span class="n">ex</span><span class="o">.</span><span class="n">nx</span><span class="p">))</span>
    <span class="n">arr</span> <span class="o">=</span> <span class="n">arr</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">arr</span>

<span class="c1"># utils.py:126:128</span>
<span class="k">class</span> <span class="nc">FeatureExtractor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Helper class for taking spatial derivatives and translating string</span>
<span class="sd">    expressions into data. Works with either pyqg.Model or xarray.Dataset.&quot;&quot;&quot;</span>
</pre></div>
</div>
</div>
</div>
<p>The above functions <code class="docutils literal notranslate"><span class="pre">extract_inputs()</span></code> and <code class="docutils literal notranslate"><span class="pre">extract_targets()</span></code> are wrappper functions of the method <code class="docutils literal notranslate"><span class="pre">extract_vars()</span></code> which creates a <code class="docutils literal notranslate"><span class="pre">FeatureExtractor</span></code> object from the dataset. This class works with <code class="docutils literal notranslate"><span class="pre">pyqg.Model</span></code> or <code class="docutils literal notranslate"><span class="pre">xarray.Dataset</span></code> as a helper class for taking spatial derivatives and translating string expressions into data since we specified the inputs and targets of the parameterized FCNN as strings. This object is used in extracting the appropriate features from the dataset and reshaping these features from an <code class="docutils literal notranslate"><span class="pre">xarray.Dataset</span></code> format to a <code class="docutils literal notranslate"><span class="pre">numpy.ndarray</span></code> representation which can then be passed into the FCNN. The main function that carries this out is <code class="docutils literal notranslate"><span class="pre">extract_feature()</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># utils.py:208:209</span>
<span class="k">def</span> <span class="nf">extract_feature</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">feature</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Evaluate a string feature, e.g. laplacian(advected(curl(u,v))).&quot;&quot;&quot;</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="standardization">
<h3>Standardization<a class="headerlink" href="#standardization" title="Permalink to this heading">#</a></h3>
<p>Now, upon extracting the relevant features from the inputs and targets of the training dataset, another preprocessing technique that is then applied on these features is standardization. This entails scaling data to fit a standard normal distribution.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># neural_networks.py:310</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">num_epochs</span><span class="o">=</span><span class="n">num_epochs</span><span class="p">,</span> <span class="o">**</span><span class="n">kw</span><span class="p">)</span>

<span class="c1"># neural_networks.py:131:135</span>
<span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">rescale</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">kw</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">rescale</span> <span class="ow">or</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;input_scale&#39;</span><span class="p">)</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_scale</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">input_scale</span> <span class="o">=</span> <span class="n">ChannelwiseScaler</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">rescale</span> <span class="ow">or</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;output_scale&#39;</span><span class="p">)</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_scale</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">output_scale</span> <span class="o">=</span> <span class="n">ChannelwiseScaler</span><span class="p">(</span><span class="n">targets</span><span class="p">,</span> <span class="n">zero_mean</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">is_zero_mean</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The function <code class="docutils literal notranslate"><span class="pre">fit()</span></code> takes in, as parameters, the extracted feature values for the inputs and targets and other additional parameters including the number of epochs to train on and whether to rescale based on the input and target values that are passed in. Each <code class="docutils literal notranslate"><span class="pre">FullyCNN</span></code> model has an input scaler and output scaler in the form of <code class="docutils literal notranslate"><span class="pre">ChannelwiseScaler</span></code> objects. The <code class="docutils literal notranslate"><span class="pre">ChannelwiseScalar</span></code> class, which inherits from its parent class, <code class="docutils literal notranslate"><span class="pre">BasicScaler</span></code>,  calculates the mean, zero spatial mean if necessary, and standard deviation along each feature channel of the the inputs and targets.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># neural_networks.py:199:209</span>
<span class="k">class</span> <span class="nc">ChannelwiseScaler</span><span class="p">(</span><span class="n">BasicScaler</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">zero_mean</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">4</span>
        <span class="k">if</span> <span class="n">zero_mean</span><span class="p">:</span>
            <span class="n">mu</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">mu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">x</span><span class="p">[:,</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])])[</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">,:,</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>
        <span class="n">sd</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">x</span><span class="p">[:,</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">std</span><span class="p">()</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])])[</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">,:,</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">sd</span><span class="p">)</span>

<span class="c1"># neural_networks.py:188</span>
<span class="k">class</span> <span class="nc">BasicScaler</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
</pre></div>
</div>
</div>
</div>
<p>These scaler objects also perform the standardization step on the data. This is done by calling <code class="docutils literal notranslate"><span class="pre">transform()</span></code> on the input and output scaler objects and passing in the input and target values, respectively.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># neural_networks.py:136:139</span>
<span class="n">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">input_scale</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">inputs</span><span class="p">),</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">output_scale</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">targets</span><span class="p">),</span>
      <span class="o">**</span><span class="n">kw</span><span class="p">)</span>

<span class="c1"># neural_networks.py:193:194</span>
<span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">mu</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">sd</span>
</pre></div>
</div>
</div>
</div>
<p>Lastly, a call is made to the function <code class="docutils literal notranslate"><span class="pre">train()</span></code> in order to kick off the training session now that the training data has been preprocessed and prepared.</p>
</div>
</div>
<div class="section" id="training-fcnns">
<h2>Training FCNNs<a class="headerlink" href="#training-fcnns" title="Permalink to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># neural_networks.py:222</span>
<span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">num_epochs</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</pre></div>
</div>
</div>
</div>
<p>The above function <code class="docutils literal notranslate"><span class="pre">train()</span></code> performs a training session on the FCNN using a sample dataset. It takes in the instance of the <code class="docutils literal notranslate"><span class="pre">FullyCNN</span></code> object as well as the preprocessed inputs and targets from the training dataset. There are additional parameters including the number of epochs to train over, the batch size, the learning rate, and device to specify whether memory will be loaded onto the GPU or CPU. These parameters can be adjusted to yield different variations of training settings. By default, the FCNNs are trained for 50 epochs over minibatches of 64 samples.</p>
<p>Examining the code in this method, first, a check is made to see whether GPU resources are available, otherwise the device falls back onto the CPU.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># neural_networks.py:223:225</span>
<span class="k">if</span> <span class="n">device</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda:0&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
    <span class="n">net</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The learning algorithm employed during training is the Adam optimizer, an adaptive learning rate optimizer and a powerful tool for improving the accuracy and speed of neural networks. The scheduling technique used during training is MultiStepLR, which decays the learning based on number of epochs reaching specific milestones. Training is evaluated on a mean squared error (MSE) loss.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># neural_networks.py:226:228</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>
<span class="n">scheduler</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">MultiStepLR</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">milestones</span><span class="o">=</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">num_epochs</span><span class="o">/</span><span class="mi">2</span><span class="p">),</span> <span class="nb">int</span><span class="p">(</span><span class="n">num_epochs</span><span class="o">*</span><span class="mi">3</span><span class="o">/</span><span class="mi">4</span><span class="p">),</span> <span class="nb">int</span><span class="p">(</span><span class="n">num_epochs</span><span class="o">*</span><span class="mi">7</span><span class="o">/</span><span class="mi">8</span><span class="p">)],</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>Each pass of the below loop performs one training epoch in which first a batch of training data is loaded by calling <code class="docutils literal notranslate"><span class="pre">minibatch()</span></code>. The optimizer’s gradients are then zeroed. Predictions from the FCNN model are made for this input batch. Calculations of the loss for that set of predictions against the actual labels on the training dataset and the backward gradients over the learning weights are made. The optimizer then adjusts the model’s learning weights based the gradients observed for the batch. Finally, the loss data is gathered and then reported as an average per-batch loss.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># neural_networks.py:211</span>
<span class="k">def</span> <span class="nf">minibatch</span><span class="p">(</span><span class="o">*</span><span class="n">arrays</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">as_tensor</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>

<span class="c1"># neural_networks.py:229:242</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
    <span class="n">epoch_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">epoch_steps</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">minibatch</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">):</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">yhat</span> <span class="o">=</span> <span class="n">net</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>
        <span class="n">ytrue</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">yhat</span><span class="p">,</span> <span class="n">ytrue</span><span class="p">)</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="n">epoch_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="n">epoch_steps</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loss after Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">epoch_loss</span><span class="o">/</span><span class="n">epoch_steps</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="saving-and-loading-fcnns">
<h2>Saving and Loading FCNNs<a class="headerlink" href="#saving-and-loading-fcnns" title="Permalink to this heading">#</a></h2>
<p>Upon completing the inital training session on these models, they are then saved to the directory path that was originally specified and an instance of the trained parameterization is returned.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># neural_networks.py:311:312</span>
<span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">directory</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;models/</span><span class="si">{</span><span class="n">z</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>To load a saved FCNN paramaterization later for further training or to make more predictions on, we instantiate a <code class="docutils literal notranslate"><span class="pre">FCNNParameterization</span></code> object, passing in the directory path to where the parameterization is saved and then read the models saved there by calling the class method <code class="docutils literal notranslate"><span class="pre">load()</span></code> from <code class="docutils literal notranslate"><span class="pre">FullyCNN</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">param</span> <span class="o">=</span> <span class="n">FCNNParameterization</span><span class="p">(</span><span class="s1">&#39;/home/jovyan/models/fcnn_qu_to_Sq2&#39;</span><span class="p">)</span>

<span class="c1"># nerual_networks.py:245:250</span>
<span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">directory</span><span class="p">,</span> <span class="n">models</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kw</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">directory</span> <span class="o">=</span> <span class="n">directory</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">models</span> <span class="o">=</span> <span class="n">models</span> <span class="k">if</span> <span class="n">models</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">[</span>
        <span class="n">FullyCNN</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="o">**</span><span class="n">kw</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">directory</span><span class="p">,</span> <span class="s2">&quot;models/*&quot;</span><span class="p">)))</span>
    <span class="p">]</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="running-predictions">
<h2>Running Predictions<a class="headerlink" href="#running-predictions" title="Permalink to this heading">#</a></h2>
<p>Having now created and trained parameterized FCNN models, we can begin making predictions on them against held-out datasets of filtered and coarse-grained high resolution simulations. We will focus our scope within these tutorials to offline testing, though we can also observe performance through online testing and metrics. The below function <code class="docutils literal notranslate"><span class="pre">test_offline()</span></code> takes in a coarsened, low-resolution dataset and then predicts the subgrid forcing targets using the parameterization. The parameterization’s predictions are then evaluated on a number of different online metrics including the coefficient of determination (<span class="math notranslate nohighlight">\(R^2\)</span>) and the Pearson correlation (<span class="math notranslate nohighlight">\(\rho\)</span>).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># utils.py:82:84</span>
<span class="k">def</span> <span class="nf">test_offline</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dataset</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Evaluate the parameterization on an offline dataset,</span>
<span class="sd">        computing a variety of metrics.&quot;&quot;&quot;</span>
</pre></div>
</div>
</div>
</div>
<p>The function then returns an <code class="docutils literal notranslate"><span class="pre">xarray.Dataset</span></code> object describing the predictions made by the parameterization is returned including a number of computed metrics.</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./notebooks"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="Applying_Filtering_and_Coarse-Graining_to_Generate_Low_Resolution_Datasets.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Applying Filtering and Coarse-Graining to Generate Low-Resolution Datasets</p>
      </div>
    </a>
    <a class="right-next"
       href="Running_Parameterized_FCNNs.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Running Parameterized FCNNs</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#initializing-and-instantiating-fcnns">Initializing and Instantiating FCNNs</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-preprocessing-and-preparation">Data Preprocessing and Preparation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#feature-extraction">Feature Extraction</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#standardization">Standardization</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#training-fcnns">Training FCNNs</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#saving-and-loading-fcnns">Saving and Loading FCNNs</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#running-predictions">Running Predictions</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By The M<sup>2</sup>LInES Community
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>