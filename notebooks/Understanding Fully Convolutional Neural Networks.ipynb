{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdf818ad-843c-448b-88b8-6ae3765f9bdb",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Understanding Fully Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf7496d-7833-4ecf-bf7d-c404391c84a4",
   "metadata": {},
   "source": [
    "Now that we have generated the coarsened, low-resolution datasets, we can now feed them as training data for our parameterized machine learning (ML) models. In this tutorial series, we will focus on one category of ML models, fully convolutional neural networks (FCNNs), though there are other strata of models that can be employed (and have been explored within the paper) including hybrid linear and symbolic regression using genetic programming. Before we begin running these models and making predictions, in this notebook, we will take the time to better our understanding of FCNNs including the initialization process, undegoing training sessions, data preparation, feature extraction and generating predictions.\n",
    "\n",
    "The code that we utilize for running parameterized ML models resides within this [repository](https://github.com/m2lines/pyqg_parameterization_benchmarks). Our main focus of interest is in the files `neural_networks.py` and `utils.py`. Starting at a high level, within `neural networks.py`, there sits the `FCNNParameterization` class. We use this class to generate parameterized FCNN models on which we can train and make predictions. Before we can begin making predictions we need to create and train our parameterized FCNNs. The class method `train_on()` takes in the dataset that the models will be initially trained on, the path to save the models to as well as the inputs and targets we are training on as strings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdaa227-0939-4dbd-adb1-a215d2644112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural_networks.py:244\n",
    "class FCNNParameterization(Parameterization):\n",
    "    \n",
    "# neural_networks.py:281:287\n",
    "@classmethod\n",
    "def train_on(cls, dataset, directory,\n",
    "        inputs=['q','u','v'], \n",
    "        targets=['q_subgrid_forcing'], # See {INSERT SECTION REFERENCE} for valid target values of sugrid forcing and flux\n",
    "        num_epochs=50,\n",
    "        zero_mean=True,\n",
    "        padding='circular', **kw): # Accepts values 'same', 'circuluar', or None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e1c7e1-1d3b-4b0d-bfd1-6c0866f7ca46",
   "metadata": {},
   "source": [
    "We can also pass in arguments for additional parameters including the number of epochs, whether the final output layers should be constrained to have zero spatial mean when predicting the subgrid forcing target, and padding technique. This method creates two `FullyCNN` objects, one for each layer of the quasigeostrophic model on which we ran simulations on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260dc0e2-f626-48ba-aa02-2184ee34f5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural_networks.py:289:299\n",
    "layers = range(len(dataset.lev))\n",
    "\n",
    "models = [\n",
    "    FullyCNN(\n",
    "        [(feat, zi) for feat in inputs for zi in layers],\n",
    "        [(feat, z) for feat in targets],\n",
    "        zero_mean=zero_mean,\n",
    "        padding=padding\n",
    "\n",
    "    ) for z in layers\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6f6cf7-47fe-4dc2-900d-eb551ebd2d03",
   "metadata": {},
   "source": [
    "Upon initializing the models, they are subsequently trained on the dataset that was passed in. This is done by first extracting the relevant input and target values from the training dataset. Since the dataset is passed as an `xarray.Dataset` we must convert it into proper `numpy.ndarray` format to feed directly into the `FullyCNN`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6342eed-0997-4ad1-a7d9-3143478c6a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural_networks.py:308:309\n",
    "X = model.extract_inputs(dataset)\n",
    "Y = model.extract_targets(dataset)\n",
    "\n",
    "# neural_networks.py:57:66\n",
    "def extract_vars(self, m, features, dtype=np.float32):\n",
    "    ex = FeatureExtractor(m)\n",
    "\n",
    "    arr = np.stack([\n",
    "        np.take(ex(feat), z, axis=-3) for feat, z in features\n",
    "    ], axis=-3)\n",
    "\n",
    "    arr = arr.reshape((-1, len(features), ex.nx, ex.nx))\n",
    "    arr = arr.astype(dtype)\n",
    "    return arr\n",
    "\n",
    "# utils.py:126:128\n",
    "class FeatureExtractor:\n",
    "    \"\"\"Helper class for taking spatial derivatives and translating string\n",
    "    expressions into data. Works with either pyqg.Model or xarray.Dataset.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5d81f6-238f-4817-acd3-19badab618a6",
   "metadata": {},
   "source": [
    "The above functions `extract_inputs()` and `extract_targets()` are wrappper functions of the method `extract_vars()` which creates a `FeatureExtractor` object from the dataset. This class works with `pyqg.Model` or `xarray.Dataset` as a helper class for taking spatial derivatives and translating string expressions into data. This object is then used in extracting the appropriate features from the dataset and reshaping these features from an `xarray.Dataset` format to a `numpy.ndarray` representation which can be passed into the model. The main function that carries this out is `extract_feature()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efb3630-bef2-4e4a-94e0-94446936e5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils.py:208:209\n",
    "def extract_feature(self, feature):\n",
    "    \"\"\"Evaluate a string feature, e.g. laplacian(advected(curl(u,v))).\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f7e488-7770-4a6f-8f41-85d5fdf6051a",
   "metadata": {},
   "source": [
    "Now, upon processing and extracting the relevant features from the inputs and targets of the training dataset, further data preparation is done in the form of normalizing these values. This is crucial and helpful in the training of our FCNNs as the different features are now on a similar scale. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8a4032-21bf-45ed-a5db-649158c1cd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural_networks.py:310\n",
    "model.fit(X, Y, num_epochs=num_epochs, **kw)\n",
    "\n",
    "# neural_networks.py:131:139\n",
    "def fit(self, inputs, targets, rescale=False, **kw):\n",
    "        if rescale or not hasattr(self, 'input_scale') or self.input_scale is None:\n",
    "            self.input_scale = ChannelwiseScaler(inputs)\n",
    "        if rescale or not hasattr(self, 'output_scale') or self.output_scale is None:\n",
    "            self.output_scale = ChannelwiseScaler(targets, zero_mean=self.is_zero_mean)\n",
    "        train(self,\n",
    "              self.input_scale.transform(inputs),\n",
    "              self.output_scale.transform(targets),\n",
    "              **kw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ab5222-e883-473a-843b-63124516ac22",
   "metadata": {},
   "source": [
    "The function `fit()` takes in as parameters the extracted values for the inputs and targets and other additional parameters including the number of epochs to train on and whether to rescale using the passed in input and target values. If there is not a `ChannelwiseScaler` object or rescaling is occurring for either the inputs or targets, then . Lastly, the function calls `train()` in order to kick off the training session now that the training data has been processed and prepared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94937e6a-8199-4457-b9d9-6da1cad43c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural_networks.py:222\n",
    "def train(net, inputs, targets, num_epochs=50, batch_size=64, learning_rate=0.001, device=None):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a8b6d0-4fcd-4a68-afba-f66c67f35bf6",
   "metadata": {},
   "source": [
    "The above function `train()` takes in"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
